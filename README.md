arpeggiate by numbers
========================

#  TODO

* infer unconditional co-occurrence probabilities (per-chord)

  * If we assume the traditional additivity, or even monotonicity, of factors, this is not tenable.
    However, there might be more exotic dimenionality reduction techniques.
    A non-exotic but unusual one is suggested by Thomsons' many-factor modle (cribbed from Shalizi's criticism of factor analysis)
    
    Another is to use a priori dissonance theory (see chordmap)

* handle velocity using  a point process marking
* [trim the data set](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#how_large_the_training_set_should_be?)
* [A list of alternate datasets](http://notes.livingthing.org/musical_corpora.html).
* handle non-negative linear field instead of bidi log field
* cyclic field generation
* Least Angle Regression would be more appropriate for these data, since they are correlated by construction.

# Methods

## Co-occurrence models

* skip grams, Bag of words etc

## Graphical models

### Directed

easy to generate from; hard to see that its natural though.

Although maybe if past notes only ever caused future notes we would be fine.
A real pianist anticipates, so maybe we should go for an unpredictable field 
and sample from it in some constrained manner.

### (Semi-?)Markov random field

We regress the conditional occurence of each note against the algrebra generated by past notes.

So that would be the regression of 2^12 interaction terms
(possibly constrained by rotational symmetry, possibly assumed e.g. linear and pairwise symmetric and hence 12*11 terms)
against 12*window past values.

Gibbs samplers of distribution of notes.

What is our energy functional? Dissonance? Dissonance per note?

Spectral autocorrelation inference?
In log-probability?
in log-RATE?

## Linear-style regression

Could do various things here;

* Generalized additive models.
* What now seems most natural: linear self-excited (discrete hawkes) processes, where we regress a *rate* kernel and possibly interaction terms (which must be positive but at least we can do logarithmic regression).
  
* but what I tried was log-linear regression of self against past

This might be quicker with [SGD](http://scikit-learn.org/stable/modules/sgd.html#sgd):

    mod = SGDClassifier(loss="log", penalty="l1", shuffle=True)

## Branching process

If we could work out how to do a periodic kernel this could be sweet.
But it is non-sparse regression in 
(tones ⨉ wavelengths ⨉ 2 (for phase)) ^ interactions.
SGD?
Expectation maximisation?
Could do a kernel-recurrence relation a la Wheatley.
* Or regress against something time-bound, perhaps...

  * decaying sinusoidal impulses? but with what period? likely several harmonics of note length.
  * interaction terms?
  * What decay? No idea. Even several superposed decays could be natural. Would have to fit term decay, which would not be linear.
  * this might possibly work via some kind of iterative method such as expectation maximisation, or just normal quasi-newton optimisation even; it would be polynomial of order no great than degree of interactions tested, which would be exactly automatically differentiable
  * How would we handle phase?

